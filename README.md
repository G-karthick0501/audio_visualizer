a baisc audio visualizer takes mic input and based on ifno extracted b and processed by web audio api.
the output is given based on array of 3d cubes using A-frame 



wrki.html does a very basic output fuction of taking in the audio input alone .
audio input tracker.py it shows the input of the frequenices taken for further processing .

futher instalments can result in having face detection using tensorflow modles for tracking of the face which would result in postioning of the output
also the kind of visulaizations that can be obtained(for e.g based on details of the audio stream 1.we can have particles of different colors moving in various speeds bouncing of the screen at extream boundaries, 2. more wavey like visulazations, 3.breaking down of concreate structures and other such visually appeling animations peratinging to ar throw a browser.)
